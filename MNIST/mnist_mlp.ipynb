{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKd9-7snpsDG"
      },
      "source": [
        "# **Baseline MLP for MNIST dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqRW5TldpuhN"
      },
      "source": [
        "**Importing Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaEsArN1pzY1"
      },
      "source": [
        "import numpy\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTlQn7u8p5LC"
      },
      "source": [
        "**load data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccqFxeZHp560",
        "outputId": "b9b35b87-7e58-4058-9618-f9d9c3189811",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgcQYUSzp9SR"
      },
      "source": [
        "**flatten 28x28 images to a 784 vector for each image **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nab5ycYTqHfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c75450c-61e1-4777-b146-06b6ec4aa0ed"
      },
      "source": [
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "print (X_train.shape)\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z5zTzcfqMB1"
      },
      "source": [
        "**normalize inputs from 0-255 to 0-1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya0mb3clqSik"
      },
      "source": [
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHbpYZODqUT7"
      },
      "source": [
        "**One Hot Encoding the outputs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r84uDvKyqX7v"
      },
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saFMnRssqbdR"
      },
      "source": [
        "**define baseline model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIx6S5PzqclX"
      },
      "source": [
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(num_pixels, input_dim=num_pixels, activation='relu'))\n",
        "\tmodel.add(Dense(num_classes,  activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohdSQ0INqfjk"
      },
      "source": [
        "**Build and Fit the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvk_Bs3PqiIL",
        "outputId": "879c5276-2266-407d-d408-0e5d0be3db82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = baseline_model()\n",
        "model.summary()\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 784)               615440    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 623290 (2.38 MB)\n",
            "Trainable params: 623290 (2.38 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "300/300 - 11s - loss: 0.2779 - accuracy: 0.9198 - val_loss: 0.1376 - val_accuracy: 0.9597 - 11s/epoch - 37ms/step\n",
            "Epoch 2/10\n",
            "300/300 - 10s - loss: 0.1106 - accuracy: 0.9684 - val_loss: 0.0998 - val_accuracy: 0.9696 - 10s/epoch - 33ms/step\n",
            "Epoch 3/10\n",
            "300/300 - 11s - loss: 0.0718 - accuracy: 0.9791 - val_loss: 0.0759 - val_accuracy: 0.9767 - 11s/epoch - 35ms/step\n",
            "Epoch 4/10\n",
            "300/300 - 10s - loss: 0.0516 - accuracy: 0.9850 - val_loss: 0.0708 - val_accuracy: 0.9791 - 10s/epoch - 33ms/step\n",
            "Epoch 5/10\n",
            "300/300 - 10s - loss: 0.0372 - accuracy: 0.9895 - val_loss: 0.0648 - val_accuracy: 0.9803 - 10s/epoch - 33ms/step\n",
            "Epoch 6/10\n",
            "300/300 - 10s - loss: 0.0279 - accuracy: 0.9923 - val_loss: 0.0622 - val_accuracy: 0.9803 - 10s/epoch - 33ms/step\n",
            "Epoch 7/10\n",
            "300/300 - 10s - loss: 0.0197 - accuracy: 0.9951 - val_loss: 0.0611 - val_accuracy: 0.9804 - 10s/epoch - 33ms/step\n",
            "Epoch 8/10\n",
            "300/300 - 10s - loss: 0.0162 - accuracy: 0.9956 - val_loss: 0.0633 - val_accuracy: 0.9799 - 10s/epoch - 33ms/step\n",
            "Epoch 9/10\n",
            "300/300 - 10s - loss: 0.0111 - accuracy: 0.9978 - val_loss: 0.0635 - val_accuracy: 0.9804 - 10s/epoch - 33ms/step\n",
            "Epoch 10/10\n",
            "300/300 - 10s - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.0578 - val_accuracy: 0.9824 - 10s/epoch - 32ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d7a60623460>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVDxQGJSqmDR"
      },
      "source": [
        "**Final evaluation of the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBLeBwHtqoBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9605fe0-de7b-45a4-e4af-4ee76efd038c"
      },
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Error: 1.76%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/deepanrajm/deep_learning.git"
      ],
      "metadata": {
        "id": "K5msHLToK_3D",
        "outputId": "58113372-7203-4315-d14c-172115fe622c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep_learning'...\n",
            "remote: Enumerating objects: 2716, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 2716 (delta 27), reused 32 (delta 15), pack-reused 2667 (from 2)\u001b[K\n",
            "Receiving objects: 100% (2716/2716), 295.03 MiB | 52.20 MiB/s, done.\n",
            "Resolving deltas: 100% (151/151), done.\n",
            "Updating files: 100% (2450/2450), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = keras.utils.load_img(\"/content/deep_learning/MNIST/7.png\", target_size=(28,28),color_mode='grayscale')\n",
        "img_array = keras.utils.img_to_array(img)\n",
        "print(img_array.shape)\n",
        "img_array = img_array.reshape(1, num_pixels).astype('float32')\n",
        "img_array = img_array / 255  # normalized\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "print (numpy.argmax(predictions))  # index position provides by argmax function"
      ],
      "metadata": {
        "id": "Hchm7beKDyJU",
        "outputId": "3942a980-6c9c-4b98-df2b-43daf2670b1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28, 1)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here as it is a NN, it gives prediction as 5 for 7 and 3 as well. So eventhough it has a higher accuracy, it is not reliable, hhence we have to go for CNN."
      ],
      "metadata": {
        "id": "BoiC4UeNOdB5"
      }
    }
  ]
}